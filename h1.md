Below is an example that shows how to load your CSV file, construct a bipartite graph from playlists and tracks, assign node features based on track audio characteristics, and then build and train a simple Graph Neural Network (GNN) recommendation model using PyTorch Geometric.

In this example, we assume that each row in your CSV corresponds to a track that appears in a playlist. We will treat:

-   **Playlist nodes** as one set (think of them as “users” in a recommendation scenario)
-   **Track nodes** as the other set (the items to be recommended)

For track nodes, we’ll use a subset of the provided audio features. (For playlist nodes, if no direct features are available, we’ll simply initialize them with zeros. In practice you might add learned embeddings or one-hot encodings based on available metadata.)

---

### 1. Loading the CSV and Building the Graph

```python
import pandas as pd
import torch
import numpy as np
from torch_geometric.data import Data

# Load your CSV file.
# Change 'path/to/your_file.csv' to the actual path.
df = pd.read_csv('path/to/your_file.csv')

# Inspect the header (should match your provided header)
print(df.columns)
# Output: Index(['track_id', 'track_name', 'track_artist', 'track_popularity',
#                'track_album_id', 'track_album_name', 'track_album_release_date',
#                'playlist_name', 'playlist_id', 'playlist_genre',
#                'playlist_subgenre', 'danceability', 'energy', 'key', 'loudness',
#                'mode', 'speechiness', 'acousticness', 'instrumentalness',
#                'liveness', 'valence', 'tempo', 'duration_ms'], dtype='object')

# --- Create Node Sets ---
# We use playlists as one set and tracks as the other.
playlist_ids = df['playlist_id'].unique()
track_ids = df['track_id'].unique()

num_playlists = len(playlist_ids)
num_tracks = len(track_ids)
total_nodes = num_playlists + num_tracks

# Create mapping dictionaries:
# For playlists, assign indices 0 .. num_playlists-1.
playlist_id_to_index = {pid: i for i, pid in enumerate(playlist_ids)}
# For tracks, assign indices num_playlists .. total_nodes-1.
track_id_to_index = {tid: i + num_playlists for i, tid in enumerate(track_ids)}

# --- Build Edges ---
# Each row represents an edge from a playlist to a track.
source_nodes = []  # playlist node indices
target_nodes = []  # track node indices
for _, row in df.iterrows():
    pid = row['playlist_id']
    tid = row['track_id']
    # Only add an edge if the mapping exists.
    if pid in playlist_id_to_index and tid in track_id_to_index:
        source_nodes.append(playlist_id_to_index[pid])
        target_nodes.append(track_id_to_index[tid])

# Create undirected edges by adding both (playlist -> track) and (track -> playlist)
edge_index = torch.tensor(
    [source_nodes + target_nodes, target_nodes + source_nodes], dtype=torch.long
)

# --- Build Node Features ---
# We will assign features only to the track nodes using audio features.
# For playlists (nodes 0 to num_playlists-1), we initialize with zeros.
# For tracks, we use a vector composed of:
#   [danceability, energy, key, loudness, mode, speechiness, acousticness,
#    instrumentalness, liveness, valence, tempo, duration_ms]
track_feature_cols = ['danceability', 'energy', 'key', 'loudness', 'mode',
                      'speechiness', 'acousticness', 'instrumentalness', 'liveness',
                      'valence', 'tempo', 'duration_ms']
num_features = len(track_feature_cols)

# Initialize a feature matrix for all nodes.
# For playlists, we use zeros; for tracks, we’ll fill in the audio features.
x = torch.zeros((total_nodes, num_features), dtype=torch.float)

# Get a DataFrame of unique track rows (using the first occurrence for each track).
track_df = df.drop_duplicates('track_id').set_index('track_id')

# Fill in track node features.
for tid, node_idx in track_id_to_index.items():
    if tid in track_df.index:
        row = track_df.loc[tid]
        # Convert the selected features into a list of floats.
        feat_values = [row[col] for col in track_feature_cols]
        x[node_idx] = torch.tensor(feat_values, dtype=torch.float)

# Now we have:
# - x: Node feature matrix (playlists have zero vectors; tracks have audio features)
# - edge_index: Graph connectivity (playlist-track interactions)
data = Data(x=x, edge_index=edge_index)
print(f"Total nodes: {total_nodes} (Playlists: {num_playlists}, Tracks: {num_tracks})")
```

---

### 2. Defining the GNN Model

Here we create a simple two-layer Graph Convolutional Network (GCN) that will update node embeddings based on neighborhood information.

```python
import torch.nn as nn
import torch.nn.functional as F
from torch_geometric.nn import GCNConv

class GNNRec(nn.Module):
    def __init__(self, in_channels, hidden_channels, out_channels):
        super(GNNRec, self).__init__()
        # First GCN layer.
        self.conv1 = GCNConv(in_channels, hidden_channels)
        # Second GCN layer.
        self.conv2 = GCNConv(hidden_channels, out_channels)

    def forward(self, x, edge_index):
        # First convolution + activation.
        x = self.conv1(x, edge_index)
        x = F.relu(x)
        # Optional dropout.
        x = F.dropout(x, training=self.training)
        # Second convolution to produce final embeddings.
        x = self.conv2(x, edge_index)
        return x

# Instantiate the model.
# in_channels equals the feature dimension (num_features).
# hidden_channels and out_channels can be tuned.
model = GNNRec(in_channels=num_features, hidden_channels=128, out_channels=64)
optimizer = torch.optim.Adam(model.parameters(), lr=0.01)
```

---

### 3. Training the GNN

We train the model using a pairwise loss strategy with negative sampling. In this bipartite setting:

-   **Positive examples:** Known edges from playlists to tracks.
-   **Negative examples:** Randomly sampled playlist–track pairs (assumed to have no interaction).

```python
# For training, we will need the positive edge indices corresponding to playlist->track edges.
# Recall that in our undirected graph, the first half of the edge_index corresponds to these.
pos_playlist_nodes = edge_index[0][:len(source_nodes)]
pos_track_nodes = edge_index[1][:len(source_nodes)]

num_pos_edges = pos_playlist_nodes.shape[0]
num_epochs = 100

model.train()
for epoch in range(num_epochs):
    optimizer.zero_grad()

    # Compute node embeddings.
    embeddings = model(data.x, data.edge_index)

    # --- Positive Samples ---
    pos_playlist_emb = embeddings[pos_playlist_nodes]
    pos_track_emb = embeddings[pos_track_nodes]
    pos_scores = (pos_playlist_emb * pos_track_emb).sum(dim=1)
    pos_loss = -torch.log(torch.sigmoid(pos_scores) + 1e-15).mean()

    # --- Negative Sampling ---
    # Randomly sample playlist and track indices.
    neg_playlist_nodes = torch.randint(0, num_playlists, (num_pos_edges,))
    neg_track_nodes = torch.randint(num_playlists, total_nodes, (num_pos_edges,))
    neg_playlist_emb = embeddings[neg_playlist_nodes]
    neg_track_emb = embeddings[neg_track_nodes]
    neg_scores = (neg_playlist_emb * neg_track_emb).sum(dim=1)
    neg_loss = -torch.log(1 - torch.sigmoid(neg_scores) + 1e-15).mean()

    # Total loss.
    loss = pos_loss + neg_loss
    loss.backward()
    optimizer.step()

    if (epoch+1) % 10 == 0:
        print(f"Epoch {epoch+1}/{num_epochs} - Loss: {loss.item():.4f}")
```

---

### 4. Inference: Making Recommendations

Once the model is trained, you can generate recommendations for a given playlist by:

1. Extracting the playlist’s embedding.
2. Computing similarity (e.g., dot product) with all track embeddings.
3. Ranking the tracks by similarity score.

Below is an example for recommending tracks for a playlist with index 0.

```python
model.eval()
with torch.no_grad():
    final_embeddings = model(data.x, data.edge_index)

# Separate playlist and track embeddings.
playlist_embeddings = final_embeddings[:num_playlists]    # indices 0 to num_playlists-1
track_embeddings = final_embeddings[num_playlists:]       # indices num_playlists to total_nodes-1

# For a given playlist (e.g., playlist with index 0), compute scores with all tracks.
playlist_id = 0  # change this to the desired playlist index
playlist_emb = playlist_embeddings[playlist_id]
scores = torch.matmul(track_embeddings, playlist_emb)

# Get the top-10 recommended track indices (relative to the track node set)
topk = 10
_, top_track_indices = torch.topk(scores, topk)
print(f"Top {topk} recommended track node indices for playlist {playlist_id}: {top_track_indices.tolist()}")

# (Optional) If you wish to map back from node indices to actual track IDs:
# Build an inverse mapping from track node index to track_id.
inv_track_map = {v: k for k, v in track_id_to_index.items()}
recommended_track_ids = [inv_track_map[idx + num_playlists] for idx in top_track_indices.tolist()]
print("Recommended track IDs:", recommended_track_ids)
```

---

### Summary

1. **Data Preparation:**

    - Load the CSV and extract unique playlists and tracks.
    - Build a bipartite graph (playlists ↔ tracks) where each edge represents a track’s inclusion in a playlist.
    - Assign audio features to track nodes and initialize playlist nodes with zeros.

2. **Model Definition:**

    - Define a simple two-layer GCN that learns node embeddings based on graph connectivity.

3. **Training:**

    - Use pairwise (positive/negative sampling) loss to encourage higher scores for true playlist–track pairs.

4. **Inference:**
    - Compute recommendations for a given playlist by ranking track embeddings via similarity (dot product).

This example serves as a starting point. In a real application, you might:

-   Enrich playlist node features (e.g., using metadata like genre or creating learnable embeddings).
-   Fine-tune the GNN architecture.
-   Experiment with more sophisticated negative sampling or loss functions.

Feel free to ask if you need further adjustments or additional explanations!
