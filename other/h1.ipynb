{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Using cached pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "Collecting numpy\n",
      "  Downloading numpy-2.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
      "Collecting torch\n",
      "  Downloading torch-2.6.0-cp310-cp310-manylinux1_x86_64.whl.metadata (28 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2025.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2025.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting filelock (from torch)\n",
      "  Downloading filelock-3.17.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./.venv/lib/python3.10/site-packages (from torch) (4.12.2)\n",
      "Collecting networkx (from torch)\n",
      "  Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting jinja2 (from torch)\n",
      "  Using cached jinja2-3.1.5-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting fsspec (from torch)\n",
      "  Downloading fsspec-2025.2.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
      "  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
      "  Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
      "  Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
      "  Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
      "  Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
      "  Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.6.2 (from torch)\n",
      "  Downloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting nvidia-nccl-cu12==2.21.5 (from torch)\n",
      "  Using cached nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.4.127 (from torch)\n",
      "  Using cached nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
      "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting triton==3.2.0 (from torch)\n",
      "  Downloading triton-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
      "Collecting sympy==1.13.1 (from torch)\n",
      "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch)\n",
      "  Using cached MarkupSafe-3.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
      "Using cached pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "Downloading numpy-2.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.6.0-cp310-cp310-manylinux1_x86_64.whl (766.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m766.7/766.7 MB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hUsing cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "Downloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl (150.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.1/150.1 MB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
      "Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "Using cached nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
      "Using cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "Downloading triton-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (253.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.1/253.1 MB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pytz-2025.1-py2.py3-none-any.whl (507 kB)\n",
      "Downloading tzdata-2025.1-py2.py3-none-any.whl (346 kB)\n",
      "Downloading filelock-3.17.0-py3-none-any.whl (16 kB)\n",
      "Downloading fsspec-2025.2.0-py3-none-any.whl (184 kB)\n",
      "Using cached jinja2-3.1.5-py3-none-any.whl (134 kB)\n",
      "Using cached networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "Using cached MarkupSafe-3.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (20 kB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: triton, pytz, nvidia-cusparselt-cu12, mpmath, tzdata, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, MarkupSafe, fsspec, filelock, pandas, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jinja2, nvidia-cusolver-cu12, torch\n",
      "Successfully installed MarkupSafe-3.0.2 filelock-3.17.0 fsspec-2025.2.0 jinja2-3.1.5 mpmath-1.3.0 networkx-3.4.2 numpy-2.2.2 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-cusparselt-cu12-0.6.2 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 pandas-2.2.3 pytz-2025.1 sympy-1.13.1 torch-2.6.0 triton-3.2.0 tzdata-2025.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas numpy torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['track_id', 'track_name', 'track_artist', 'track_popularity',\n",
      "       'track_album_id', 'track_album_name', 'track_album_release_date',\n",
      "       'playlist_name', 'playlist_id', 'playlist_genre', 'playlist_subgenre',\n",
      "       'danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness',\n",
      "       'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo',\n",
      "       'duration_ms'],\n",
      "      dtype='object')\n",
      "Total nodes: 28827 (Playlists: 471, Tracks: 28356)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# Load your CSV file.\n",
    "# Change 'path/to/your_file.csv' to the actual path.\n",
    "df = pd.read_csv('spotify_songs.csv')\n",
    "\n",
    "# Inspect the header (should match your provided header)\n",
    "print(df.columns)\n",
    "# Output: Index(['track_id', 'track_name', 'track_artist', 'track_popularity',\n",
    "#                'track_album_id', 'track_album_name', 'track_album_release_date',\n",
    "#                'playlist_name', 'playlist_id', 'playlist_genre',\n",
    "#                'playlist_subgenre', 'danceability', 'energy', 'key', 'loudness',\n",
    "#                'mode', 'speechiness', 'acousticness', 'instrumentalness',\n",
    "#                'liveness', 'valence', 'tempo', 'duration_ms'], dtype='object')\n",
    "\n",
    "# --- Create Node Sets ---\n",
    "# We use playlists as one set and tracks as the other.\n",
    "playlist_ids = df['playlist_id'].unique()\n",
    "track_ids = df['track_id'].unique()\n",
    "\n",
    "num_playlists = len(playlist_ids)\n",
    "num_tracks = len(track_ids)\n",
    "total_nodes = num_playlists + num_tracks\n",
    "\n",
    "# Create mapping dictionaries:\n",
    "# For playlists, assign indices 0 .. num_playlists-1.\n",
    "playlist_id_to_index = {pid: i for i, pid in enumerate(playlist_ids)}\n",
    "# For tracks, assign indices num_playlists .. total_nodes-1.\n",
    "track_id_to_index = {tid: i + num_playlists for i, tid in enumerate(track_ids)}\n",
    "\n",
    "# --- Build Edges ---\n",
    "# Each row represents an edge from a playlist to a track.\n",
    "source_nodes = []  # playlist node indices\n",
    "target_nodes = []  # track node indices\n",
    "for _, row in df.iterrows():\n",
    "    pid = row['playlist_id']\n",
    "    tid = row['track_id']\n",
    "    # Only add an edge if the mapping exists.\n",
    "    if pid in playlist_id_to_index and tid in track_id_to_index:\n",
    "        source_nodes.append(playlist_id_to_index[pid])\n",
    "        target_nodes.append(track_id_to_index[tid])\n",
    "\n",
    "# Create undirected edges by adding both (playlist -> track) and (track -> playlist)\n",
    "edge_index = torch.tensor(\n",
    "    [source_nodes + target_nodes, target_nodes + source_nodes], dtype=torch.long\n",
    ")\n",
    "\n",
    "# --- Build Node Features ---\n",
    "# We will assign features only to the track nodes using audio features.\n",
    "# For playlists (nodes 0 to num_playlists-1), we initialize with zeros.\n",
    "# For tracks, we use a vector composed of:\n",
    "#   [danceability, energy, key, loudness, mode, speechiness, acousticness,\n",
    "#    instrumentalness, liveness, valence, tempo, duration_ms]\n",
    "track_feature_cols = ['danceability', 'energy', 'key', 'loudness', 'mode',\n",
    "                      'speechiness', 'acousticness', 'instrumentalness', 'liveness',\n",
    "                      'valence', 'tempo', 'duration_ms']\n",
    "num_features = len(track_feature_cols)\n",
    "\n",
    "# Initialize a feature matrix for all nodes.\n",
    "# For playlists, we use zeros; for tracks, we’ll fill in the audio features.\n",
    "x = torch.zeros((total_nodes, num_features), dtype=torch.float)\n",
    "\n",
    "# Get a DataFrame of unique track rows (using the first occurrence for each track).\n",
    "track_df = df.drop_duplicates('track_id').set_index('track_id')\n",
    "\n",
    "# Fill in track node features.\n",
    "for tid, node_idx in track_id_to_index.items():\n",
    "    if tid in track_df.index:\n",
    "        row = track_df.loc[tid]\n",
    "        # Convert the selected features into a list of floats.\n",
    "        feat_values = [row[col] for col in track_feature_cols]\n",
    "        x[node_idx] = torch.tensor(feat_values, dtype=torch.float)\n",
    "\n",
    "# Now we have:\n",
    "# - x: Node feature matrix (playlists have zero vectors; tracks have audio features)\n",
    "# - edge_index: Graph connectivity (playlist-track interactions)\n",
    "data = Data(x=x, edge_index=edge_index)\n",
    "print(f\"Total nodes: {total_nodes} (Playlists: {num_playlists}, Tracks: {num_tracks})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class GNNRec(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super(GNNRec, self).__init__()\n",
    "        # First GCN layer.\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        # Second GCN layer.\n",
    "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
    "        \n",
    "    def forward(self, x, edge_index):\n",
    "        # First convolution + activation.\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        # Optional dropout.\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        # Second convolution to produce final embeddings.\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "# Instantiate the model.\n",
    "# in_channels equals the feature dimension (num_features).\n",
    "# hidden_channels and out_channels can be tuned.\n",
    "model = GNNRec(in_channels=num_features, hidden_channels=128, out_channels=64)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100 - Loss: 34.5388\n",
      "Epoch 20/100 - Loss: 34.5388\n",
      "Epoch 30/100 - Loss: 34.5388\n",
      "Epoch 40/100 - Loss: 34.5388\n",
      "Epoch 50/100 - Loss: 34.5388\n",
      "Epoch 60/100 - Loss: 34.5388\n",
      "Epoch 70/100 - Loss: 34.5388\n",
      "Epoch 80/100 - Loss: 34.5388\n",
      "Epoch 90/100 - Loss: 34.5388\n",
      "Epoch 100/100 - Loss: 34.5388\n"
     ]
    }
   ],
   "source": [
    "# For training, we will need the positive edge indices corresponding to playlist->track edges.\n",
    "# Recall that in our undirected graph, the first half of the edge_index corresponds to these.\n",
    "pos_playlist_nodes = edge_index[0][:len(source_nodes)]\n",
    "pos_track_nodes = edge_index[1][:len(source_nodes)]\n",
    "\n",
    "num_pos_edges = pos_playlist_nodes.shape[0]\n",
    "num_epochs = 100\n",
    "\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Compute node embeddings.\n",
    "    embeddings = model(data.x, data.edge_index)\n",
    "    \n",
    "    # --- Positive Samples ---\n",
    "    pos_playlist_emb = embeddings[pos_playlist_nodes]\n",
    "    pos_track_emb = embeddings[pos_track_nodes]\n",
    "    pos_scores = (pos_playlist_emb * pos_track_emb).sum(dim=1)\n",
    "    pos_loss = -torch.log(torch.sigmoid(pos_scores) + 1e-15).mean()\n",
    "    \n",
    "    # --- Negative Sampling ---\n",
    "    # Randomly sample playlist and track indices.\n",
    "    neg_playlist_nodes = torch.randint(0, num_playlists, (num_pos_edges,))\n",
    "    neg_track_nodes = torch.randint(num_playlists, total_nodes, (num_pos_edges,))\n",
    "    neg_playlist_emb = embeddings[neg_playlist_nodes]\n",
    "    neg_track_emb = embeddings[neg_track_nodes]\n",
    "    neg_scores = (neg_playlist_emb * neg_track_emb).sum(dim=1)\n",
    "    neg_loss = -torch.log(1 - torch.sigmoid(neg_scores) + 1e-15).mean()\n",
    "    \n",
    "    # Total loss.\n",
    "    loss = pos_loss + neg_loss\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} - Loss: {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 recommended track node indices for playlist 0: [3403, 133, 344, 28158, 28185, 28204, 28138, 28184, 28202, 28159]\n",
      "Recommended Track Names: [\"Sweet Child O' Mine\", 'Closer (feat. Halsey)', 'bad guy', 'Hypnotic Energy', 'Blabla', 'El Segundo', 'Toro - Original Mix', 'Mental Vortex', 'Samurai', 'Billy Boy']\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    final_embeddings = model(data.x, data.edge_index)\n",
    "\n",
    "# Separate playlist and track embeddings.\n",
    "playlist_embeddings = final_embeddings[:num_playlists]  # indices 0 to num_playlists-1\n",
    "track_embeddings = final_embeddings[\n",
    "    num_playlists:\n",
    "]  # indices num_playlists to total_nodes-1\n",
    "\n",
    "# For a given playlist (e.g., playlist with index 0), compute scores with all tracks.\n",
    "playlist_index = 0  # change this to the desired playlist index\n",
    "playlist_emb = playlist_embeddings[playlist_index]\n",
    "scores = torch.matmul(track_embeddings, playlist_emb)\n",
    "\n",
    "# Get the top-10 recommended track indices (relative to the track node set)\n",
    "topk = 10\n",
    "_, top_track_indices = torch.topk(scores, topk)\n",
    "print(\n",
    "    f\"Top {topk} recommended track node indices for playlist {playlist_index}: {top_track_indices.tolist()}\"\n",
    ")\n",
    "\n",
    "# Build an inverse mapping from track node index to track_id.\n",
    "# Recall: track nodes are numbered from num_playlists to total_nodes-1.\n",
    "inv_track_map = {v: k for k, v in track_id_to_index.items()}\n",
    "\n",
    "# Retrieve the track IDs corresponding to the recommended track node indices,\n",
    "# and then use the track metadata DataFrame (`track_df`) to get the track names.\n",
    "recommended_track_names = []\n",
    "for idx in top_track_indices.tolist():\n",
    "    # Convert the local track index (0...num_tracks-1) to the actual node index.\n",
    "    node_index = idx + num_playlists\n",
    "    track_id = inv_track_map.get(node_index)\n",
    "    if track_id is not None and track_id in track_df.index:\n",
    "        # Assuming 'track_name' is the column with the song name.\n",
    "        track_name = track_df.loc[track_id][\"track_name\"]\n",
    "        recommended_track_names.append(track_name)\n",
    "    else:\n",
    "        recommended_track_names.append(\"Unknown Track\")\n",
    "\n",
    "print(\"Recommended Track Names:\", recommended_track_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 recommended songs similar to 'Memories' are:\n",
      "1. Sweet Child O' Mine\n",
      "2. Closer (feat. Halsey)\n",
      "3. bad guy\n",
      "4. Hypnotic Energy\n",
      "5. Blabla\n",
      "6. El Segundo\n",
      "7. Toro - Original Mix\n",
      "8. Mental Vortex\n",
      "9. Samurai\n",
      "10. Billy Boy\n",
      "\n",
      "\n",
      "\n",
      "Top 10 recommended songs similar to 'Body On My' are:\n",
      "1. Sweet Child O' Mine\n",
      "2. Closer (feat. Halsey)\n",
      "3. bad guy\n",
      "4. Hypnotic Energy\n",
      "5. Blabla\n",
      "6. El Segundo\n",
      "7. Toro - Original Mix\n",
      "8. Mental Vortex\n",
      "9. Samurai\n",
      "10. Billy Boy\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Ensure your model is in evaluation mode.\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # Compute the final node embeddings for all nodes.\n",
    "    final_embeddings = model(data.x, data.edge_index)\n",
    "\n",
    "# Separate playlist and track embeddings.\n",
    "# (Playlist nodes: indices 0 to num_playlists-1;\n",
    "#  Track nodes: indices num_playlists to total_nodes-1)\n",
    "playlist_embeddings = final_embeddings[:num_playlists]\n",
    "track_embeddings = final_embeddings[num_playlists:]\n",
    "\n",
    "# Build an inverse mapping from track node index (global index) to track_id.\n",
    "inv_track_map = {v: k for k, v in track_id_to_index.items()}\n",
    "\n",
    "def get_track_node_index_by_name(query_name):\n",
    "    \"\"\"\n",
    "    Given a song name, try to locate its track_id in track_df and return\n",
    "    the corresponding node index using the track_id_to_index mapping.\n",
    "    The search is case-insensitive and requires an exact match.\n",
    "    \"\"\"\n",
    "    # Use a case-insensitive match on the 'track_name' column.\n",
    "    matches = track_df[track_df['track_name'].str.lower() == query_name.lower()]\n",
    "    if matches.empty:\n",
    "        return None, None\n",
    "    else:\n",
    "        # Use the first match.\n",
    "        track_id = matches.index[0]\n",
    "        node_index = track_id_to_index.get(track_id)\n",
    "        return track_id, node_index\n",
    "\n",
    "# --- Interactive Query Section ---\n",
    "while True:\n",
    "    query_name = input(\"Enter a song name (or 'quit' to exit): \").strip()\n",
    "    if query_name.lower() == 'quit':\n",
    "        break\n",
    "\n",
    "    track_id, node_index = get_track_node_index_by_name(query_name)\n",
    "    if node_index is None:\n",
    "        print(\"Song not found in the dataset. Please try again.\")\n",
    "        continue\n",
    "\n",
    "    # Retrieve the embedding of the input song.\n",
    "    # (node_index is the global node index.)\n",
    "    song_embedding = final_embeddings[node_index]\n",
    "\n",
    "    # Compute similarity (dot product) between the input song embedding\n",
    "    # and all track embeddings.\n",
    "    # track_embeddings is of size [num_tracks, embedding_dim]\n",
    "    similarities = torch.matmul(track_embeddings, song_embedding)\n",
    "\n",
    "    # Since the input song is among the track embeddings, we remove it from the results.\n",
    "    # Compute the local index of the song within the track_embeddings matrix.\n",
    "    local_index = node_index - num_playlists\n",
    "    similarities[local_index] = -float(\"inf\")  # exclude itself\n",
    "\n",
    "    # Get the top-10 similar track indices (local indices within track_embeddings)\n",
    "    topk = 10\n",
    "    top_sim_values, top_indices = torch.topk(similarities, topk)\n",
    "\n",
    "    # Map local indices back to global node indices and then to track IDs,\n",
    "    # then retrieve the song names from track_df.\n",
    "    recommended_track_names = []\n",
    "    for local_idx in top_indices.tolist():\n",
    "        global_node_idx = local_idx + num_playlists\n",
    "        rec_track_id = inv_track_map.get(global_node_idx, None)\n",
    "        if rec_track_id is not None:\n",
    "            # Get the track name from track_df.\n",
    "            rec_track_name = track_df.loc[rec_track_id]['track_name']\n",
    "            recommended_track_names.append(rec_track_name)\n",
    "        else:\n",
    "            recommended_track_names.append(\"Unknown Track\")\n",
    "\n",
    "    print(\"\\nTop 10 recommended songs similar to '{}' are:\".format(query_name))\n",
    "    for i, name in enumerate(recommended_track_names, 1):\n",
    "        print(f\"{i}. {name}\")\n",
    "    print(\"\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
